import re
import string
from collections import Counter, defaultdict

import nltk


# From: https://www.datacamp.com/tutorial/text-analytics-beginners-nltk
# import libraries
import pandas as pd
from nltk.corpus import stopwords
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize

from random import choice
from string import ascii_letters, digits

random_string = lambda n=8: ''.join(choice(ascii_letters + digits) for _ in range(n))

def init_nltk():
    # Download the necessary NLTK resources
    # Generated by Copilot
    required_resources = {
        'tokenizers': ['punkt'],
        'sentiment': ['vader_lexicon'],
        'corpora': ['stopwords', 'wordnet'],
        
    }
    for key, value in required_resources.items():
        for resource in value:
            try:
                # check first
                nltk.data.find(f'{key}/{resource}')
            except:
                nltk.download(resource) # will only download if not already present


def create_summary(question, n=3):
    try:
        # Remove numbers and convert to lowercase
        cleaned_text = re.sub(r'\d+', '', question.lower())
        
        # Remove punctuation
        cleaned_text = ''.join(char for char in cleaned_text if char not in string.punctuation)

        
        # Tokenize and remove stopwords
        stop_words = {'what', 'where', 'when', 'who', 'why', 'how', 'the', 'a', 'an', 'is', 'in', 'it', 'of', 'to'}.union(set(stopwords.words('english')))
        tokens = [(word, idx) for idx,word in enumerate(word_tokenize(cleaned_text)) 
                if len(word)>1 and word.isalpha() and word not in stop_words]
        
        # Calculate word frequencies
        word_freq = Counter(t[0] for t in tokens)
        
        # Get top 3 words
        top_3_words = [word for word, _ in word_freq.most_common(n)]
        # Sort by first appearance
        top_3_words.sort(key=lambda x: [t[0] for t in tokens].index(x))
        
        return ' '.join(top_3_words)
    except:
        return "Error in processing the question." + random_string(4)



